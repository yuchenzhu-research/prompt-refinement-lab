# Prompt Refinement Lab

一个用于记录与实践 **提示词工程（Prompt Engineering）** 的实验仓库。

本仓库的目标不是追求“完美提示词”，而是通过 **版本管理、测试与复盘**，探索提示词在不同应用场景下的稳定性、可迁移性与工程化路径。

内容以中文为主。

---

## 仓库动机

在正式进入科研或长期研究之前，我希望通过一个**低风险的小项目**，系统性练习以下能力：

- 将模糊的使用经验整理为可描述、可复现的方法
- 对提示词进行版本化管理与多轮迭代
- 构建可复用的改进流程，而非一次性结果
- 明确区分「极限测试」与「日常使用」的目标差异

因此建立了这个实验仓库。

---


## 项目结构

```text
prompt-refinement-lab/
├── aurora-of-words/   # 语言表达与英语提示词实验（侧重表达、选词与风格控制）
├── cpp-benchmark/     # C++ / Python 场景下的提示词与代码生成、优化与对比实验
├── a7m5-workflow/     # 索尼 A7M5 摄影 / 视频工作流相关的提示词工程化研究
└── relationship/      # 关系与沟通场景下的提示词分析、生成与应对策略实验
```

> 目录结构用于区分不同应用场景下的提示词实验。

---

## 子项目说明

- **aurora-of-words**  
  语言表达与英语提示词实验，侧重表达结构、选词策略与风格控制。

- **cpp-benchmark**  
  C / C++（及部分 Python）场景下的提示词实验，用于比较不同提示词对代码生成与优化效果的影响。

- **a7m5-workflow**  
  索尼 A7M5 摄影 / 视频工作流相关的提示词工程化研究，关注参数、流程与任务拆解。

- **relationship**  
  关系与沟通场景下的提示词分析、生成与应对策略实验。

---

## 实验组成与材料

每个子项目通常包含以下内容：

- 原始提示词（baseline）
- 多轮迭代后的提示词版本
- 测试用问题集（benchmark）
- 输出结果与复盘记录（PDF / txt）

---

## 使用的模型与环境

- **ChatGPT 5.2（thinking）**
- **Gemini 3 Pro / Deep Research**

不同模型在信息整合、结构生成与风格控制方面存在差异。  
本仓库的部分流程刻意利用这些差异进行交叉验证与对比。

---

## 提示词改进的一般流程

以下流程并非固定模板，而是在一次完整实践中逐步收敛出的路径：

1. **确定稳定的初始提示词**  
   作为 baseline，避免在无参照的情况下直接优化。

2. **由人先总结问题，再交给模型改进**  
   例如结构不清晰、冗余、风格不一致等，而非完全重写。

3. **引入外部信息源进行补充**  
   通过搜索或资料整理，避免只在模型内部反复微调。

4. **使用 Deep Research 进行信息深挖**  
   将研究型提示词交由另一模型进行深度检索，再回流迭代。

5. **构造 benchmark 进行测试**  
   由模型自主出题，测试提示词在高压力条件下的表现，并结构化保存结果。

6. **评分与复盘，进入下一轮迭代**  
   利用评分结果反向定位提示词薄弱点，形成闭环。

---

## 关于 benchmark 的说明

本仓库中的 benchmark 更多用于**测试提示词的极限能力**，而非模拟高频日常使用场景。

例如在摄影场景中：

- 测试集可能包含极端复杂的拍摄条件（混合光源、逆光、雨夜等）
- 而日常使用往往处于更简单、可控的环境

因此，提示词的最终优化目标始终以 **真实使用场景** 为准，而非单纯追求极限测试下的表现。

---

## 当前反思

在早期实验中，曾因过度自信而未完整保留“真正的原始版本”，导致后续无法回退到最初偏好的风格。

这一问题促使我在后续子项目中更加重视 **版本保存、过程记录与可回溯性**。

---

## 状态说明

本仓库仍处于持续整理与迭代中：

- 部分提示词尚未定型
- 不同子项目的流程细节可能存在差异

本仓库更偏向 **过程型记录**，而非最终成品展示。
